{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00d90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import shapiro\n",
    "from scipy import signal\n",
    "from scipy.signal import butter\n",
    "from scipy.signal import bode\n",
    "import scipy.interpolate\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "from scipy.interpolate.rbf import Rbf\n",
    "import metpy\n",
    "from metpy.interpolate import interpolate_to_grid\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from joblib import Parallel, delayed\n",
    "import time as TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d3f3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculate minutes between utc and utc0 (time format: \"YYYY-mm-ddT00:00:00Z\")\n",
    "\n",
    "def utc_to_minutes(utc, utc0):\n",
    "    minutes = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").minute\n",
    "    minutes0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").minute\n",
    "    hours = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").hour\n",
    "    hours0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").hour\n",
    "    month0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").month\n",
    "    month = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").month\n",
    "    days = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").day\n",
    "    year0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").year\n",
    "    year = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").year\n",
    "    \n",
    "    if month0 == month:\n",
    "        days -= datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").day\n",
    "    if  month0!=month and year0 == year:\n",
    "        if month0 == 1 or month0 ==3 or month0 == 5 or month0 == 7 or month0 == 8 or month0 == 10 or month0 == 12:\n",
    "            days += 31 - datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").day\n",
    "        if month0 == 2 or month0 == 4 or month0 == 6 or month0 == 9 or month0 == 11:\n",
    "            days += 30 - datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").day\n",
    "    \n",
    "    if year0 != year:\n",
    "        dmonth = month + month0%12\n",
    "        i = 0\n",
    "        while i <dmonth:\n",
    "            if i == 0:\n",
    "                if month0 == 1 or month0 ==3 or month0 == 5 or month0 == 7 or month0 == 8 or month0 == 10 or month0 == 12:\n",
    "                    days += 31 - datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").day\n",
    "                if month0 == 2 or month0 == 4 or month0 == 6 or month0 == 9 or month0 == 11:\n",
    "                    days += 30 - datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").day\n",
    "            else:\n",
    "                if month0 + i == 1 or month0 + i ==3 or month0 + i== 5 or month0 + i == 7 or month0 + i == 8 or month0 + i == 10 or month0 + i == 12:\n",
    "                    days += 31\n",
    "                if month0 + i  == 2 or month0 + i == 4 or month0 + i == 6 or month0 + i == 9 or month0 + i == 11:\n",
    "                    days += 30\n",
    "            i += 1\n",
    "    minutes_tot = (minutes-minutes0) + (hours-hours0)*60 + days*24*60\n",
    "    \n",
    "    return minutes_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a9a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculate utc after \"minutes_\" from utc0 (time format: \"YYYY-mm-ddT00:00:00Z\")\n",
    "\n",
    "def minutes_to_utc(minutes_,utc0):\n",
    "    seconds0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").second\n",
    "    minutes0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").minute\n",
    "    hours0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").hour\n",
    "    month0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").month\n",
    "    days0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").day\n",
    "    year0 = datetime.strptime(utc0, \"%Y-%m-%dT%H:%M:%SZ\").year\n",
    "    \n",
    "    Minutes = (minutes0 + minutes_)%60\n",
    "    Hours = (hours0+ (minutes0 + minutes_ )//60)%24\n",
    "    a = (hours0+ (minutes0 + minutes_ )//60)//24\n",
    "    days = days0 + a\n",
    "    Seconds = seconds0\n",
    "    month = month0\n",
    "    Year = year0   \n",
    "    \n",
    "    if month0 == 1 or month0 ==3 or month0 == 5 or month0 == 7 or month0 == 8 or month0 == 10 or month0 == 12:\n",
    "        if days > 31:            \n",
    "            if month ==12:\n",
    "                Year+= 1\n",
    "                month = 1\n",
    "                days = days%31\n",
    "            else:\n",
    "                month +=1\n",
    "                days = days%31\n",
    "    if month0 == 2 or month0 == 4 or month0 == 6 or month0 == 9 or month0 == 11:        \n",
    "        if days > 30:\n",
    "            month+=1\n",
    "            days = days%30\n",
    "            \n",
    "    Y = np.int(Year)\n",
    "    m = np.int(month)\n",
    "    d = np.int(days)\n",
    "    H = np.int(Hours)\n",
    "    M = np.int(Minutes)\n",
    "    S = np.int(Seconds)\n",
    "    utc = datetime(Y,m,d,H,M,S)\n",
    "    utc_ = utc.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    return utc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4569c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "##convert time format \"YYYY-mm-ddT00:00:00Z\" to \"YYYY-mm-dd 00:00:00\"\n",
    "\n",
    "def utc_(utc):\n",
    "    seconds = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").second\n",
    "    minutes = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").minute\n",
    "    hours = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").hour\n",
    "    month = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").month\n",
    "    days = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").day\n",
    "    year = datetime.strptime(utc, \"%Y-%m-%dT%H:%M:%SZ\").year\n",
    "    Y = np.int(year)\n",
    "    m = np.int(month)\n",
    "    d = np.int(days)\n",
    "    H = np.int(hours)\n",
    "    M = np.int(minutes)\n",
    "    S = np.int(seconds)\n",
    "    utc = datetime(Y,m,d,H,M,S)\n",
    "    utc_ = utc.strftime(\"%Y_%m_%d_%H_%M_%S_\")\n",
    "    \n",
    "    return utc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a95201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in:\n",
    "## floater : drifter ID\n",
    "## data : data from https://www.aoml.noaa.gov/phod/gdp/index.php, csv file with format:\n",
    "##        \"platform_code\",\"platform_type\",\"time\" (UTC), \"latitude\" (degrees north), \"longitude\" (degrees east), \n",
    "##        \"sst\" (degrees Celcius), \"slp\" (Hectopascal), \"long360\" (degrees east)\n",
    "## t0 : start time (YYYY-mm-ddT00:00:00Z)\n",
    "## t : end time (YYYY-mm-ddT00:00:00Z)\n",
    "## lat0 , lat , long0, long: latitude and longitude range\n",
    "## i : variable iterating through \"data\"\n",
    "\n",
    "## out:\n",
    "## floater.csv : csv file with format: \"time\", \"lat\", \"long\", \"temp\", \"pressure\"\n",
    "##               containing all data points  of drifter \"floater\" between t0, t in range of lat0, lat, long0, long\n",
    "## returns:\n",
    "## j : number of datapoints found for drifter \"floater\"\n",
    "## i : variable iterating through \"data\"\n",
    "\n",
    "\n",
    "def floater_csv(floater,data, t0,t, lat0, lat, long0, long,i, path0):\n",
    "    \n",
    "    ## number of data points found corresponding to drifter \"floater\"\n",
    "    j = 0\n",
    "    \n",
    "    ## iterate through \"data\" until \"platform_code\" corresponds to floater\n",
    "    while data['platform_code'][i]!=floater and i < len(data)-1:\n",
    "        i+=1\n",
    "    \n",
    "    header = ['time','lat','long','temp','pressure']\n",
    "    ##time step between selected initial time and time of first datapoint in \"data\" ( in minutes)\n",
    "    T0 = utc_to_minutes(t0,data['time'][1]) \n",
    "    ##time step between selected end time and time of first datapoint in \"data\" ( in minutes)\n",
    "    T = utc_to_minutes(t,data['time'][1])\n",
    "\n",
    "    ## iterate through \"data\" until t(i) is larger than T0\n",
    "    while T0 > utc_to_minutes(data['time'][i],data['time'][1] ):\n",
    "        i+=1\n",
    "        \n",
    "    ## iterate through \"data\", write data points into csv file \"floater\".csv until t(i) is larger than T\n",
    "    while data['platform_code'][i]==floater and utc_to_minutes(data['time'][i],data['time'][1] ) < T:\n",
    "        \n",
    "        ## valid data point number \"j\" != 0 is added (not first)\n",
    "        if j != 0 and float(data['latitude'][i])<=lat and float(data['latitude'][i])>=lat0 and float(data['longitude'][i])<=long and float(data['longitude'][i])>=long0 and utc_to_minutes(data['time'][i],data['time'][i-1])>= 60:                \n",
    "            with open('%sunfiltered/%s_unfiltered.csv' % (path0,int(data['platform_code'][i])),'a',newline='') as f:            \n",
    "                writer = csv.writer(f)    \n",
    "                writer.writerow([data['time'][i],data['latitude'][i],data['longitude'][i],data['sst'][i],data['slp'][i]])\n",
    "            j+=1\n",
    "            \n",
    "        ## valid data point number \"j\" = 0 is added (first)\n",
    "        if j == 0 and float(data['latitude'][i])<=lat and float(data['latitude'][i])>=lat0 and float(data['longitude'][i])<=long and float(data['longitude'][i])>=long0:\n",
    "            with open('%sunfiltered/%s_unfiltered.csv' % (path0,int(data['platform_code'][i])),'w',newline='') as f:           \n",
    "                writer = csv.writer(f)                \n",
    "                writer.writerow(header)                \n",
    "                writer.writerow([data['time'][i],data['latitude'][i],data['longitude'][i],data['sst'][i],data['slp'][i]])       \n",
    "            j+=1       \n",
    "        i+=1\n",
    "    \n",
    "    return j,i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6852c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in:\n",
    "## floaters : drifter ID\n",
    "## time0 : start time (YYYY-mm-ddT00:00:00Z)\n",
    "## time : end time (YYYY-mm-ddT00:00:00Z)\n",
    "\n",
    "## out:\n",
    "## floaters.csv : data points with: \n",
    "##                - displacement to last smaller than 0.01 km\n",
    "##                - delta t to last larger than 12h\n",
    "##                - velocity to last smaller than 0.05 km/h\n",
    "##                are removed (conditions for valid data point not met)\n",
    "## returns:\n",
    "## len(data) : number of datapoints in csv file\n",
    "\n",
    "\n",
    "def filter_(floaters,time0,time, path0):\n",
    "    data = pd.read_csv(\"%sunfiltered/%s_unfiltered.csv\" % (path0,floaters))\n",
    "    R = 6371\n",
    "    j = 1\n",
    "    k = 1\n",
    "    Vel = [0]\n",
    "    Dt = [0]\n",
    "    noise = []\n",
    "    gap = 0\n",
    "    gap1 = 0\n",
    "    \n",
    "    ## iterate through \"data\" (in backwards time)\n",
    "    while j <= len(data) and j + k <= len(data):\n",
    "        lat0 = data['lat'][len(data)-j]\n",
    "        rlat0 = math.radians(lat0)\n",
    "        lat = data['lat'][len(data)-j-k]\n",
    "        rlat = math.radians(lat)\n",
    "        long0 = data['long'][len(data)-j]\n",
    "        rlong0 = math.radians(long0)\n",
    "        long = data['long'][len(data)-j-k]\n",
    "        rlong = math.radians(long)\n",
    "        \n",
    "        ##distance between data points j, j+k (in km)\n",
    "        d = 2*R*np.arcsin(np.sqrt((np.sin((rlat-rlat0)/2))**2 + np.cos(rlat0)*np.cos(rlat)*(np.sin((rlong-rlong0)/2))**2))\n",
    "        \n",
    "        ##time step between data points j, j+k ( in hours)\n",
    "        dt = int(utc_to_minutes(data['time'][len(data)-j],data['time'][len(data)-j-k]))/60\n",
    "        vel = d/dt\n",
    "        \n",
    "        ## if conditions for valid data point not met add data point j+k to \"noise\" and increment k:\n",
    "        \n",
    "        ## condition to obtain preprocessed drifter data:\n",
    "        if dt > 12 or  round(dt) == 0 or vel > 20 or d <= 0.01:            \n",
    "        ## condition to obtain raw drifter data\n",
    "        #if d == 0:\n",
    "        \n",
    "            noise = np.append(noise,len(data)-j-k)\n",
    "            k += 1\n",
    "            if dt > 12:\n",
    "                gap = 1\n",
    "        ## if conditions met reset k to 1, increment j:\n",
    "        \n",
    "        ##condition to obtain preprocessed drifter data:\n",
    "        if dt <= 12 and round(dt) != 0 and vel <= 20 and d > 0.01:\n",
    "        ##condition to obtain raw drifter data:\n",
    "        #if d != 0:\n",
    "            \n",
    "            Dt = np.append(Dt,dt)\n",
    "            Vel = np.append(Vel,vel)\n",
    "            j += 1\n",
    "            if k != 1:\n",
    "                j = j+k-1\n",
    "            k = 1   \n",
    "            \n",
    "    noise = np.int_(noise)\n",
    "    \n",
    "    ## remove data points in \"noise\"\n",
    "    datapoints = np.arange(0,len(data),1)\n",
    "    datapoints_1 = [x for x in datapoints if x not in noise]\n",
    "    data = data.drop(index = noise)\n",
    "    \n",
    "    ## if first/last data point more than 12 hours after/before desired start, end time \n",
    "    ## remove all data points ( drifter not in temporal range)\n",
    "    if utc_to_minutes(time,data['time'][np.max(datapoints_1)])/60 > 12 or utc_to_minutes(data['time'][np.min(datapoints_1)],time0)/60 > 12:\n",
    "        data = data.drop(index = datapoints_1)\n",
    "        gap1 = 1\n",
    "    data.to_csv(\"%sfiltered/%s.csv\" % (path0,floaters))\n",
    "\n",
    "    return len(data), gap, gap1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc1d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from gitbhub\n",
    "\n",
    "\n",
    "def filter_data(lat, long, cutoff, lat_mean, fs):\n",
    "    \n",
    "    for c in range(len(long)-1):\n",
    "        \n",
    "        # sampling frequency of drifters: 1/6hours\n",
    "        #fs = f\n",
    "        \n",
    "        # Cut-off period\n",
    "        ## filter with average latitude of drifter trajectory\n",
    "        T = min(cutoff*2*np.pi/(2*7.27*10**(-5)*60*60*np.abs(np.sin(np.nanmean(list(lat))*np.pi/180))), 5*24)\n",
    "        ## filter with average latitude of spatial range considered\n",
    "        #T = min(cutoff*2*np.pi/(2*7.27*10**(-5)*60*60*np.abs(np.sin(lat_mean*np.pi/180))), 5*24)\n",
    "        \n",
    "        f = 1/T\n",
    "        \n",
    "        # low-pass frequency\n",
    "        lowpass_frequency = f/(fs/2)\n",
    "        \n",
    "        # Check if there is a crossing from -180° to 180° (or viceversa) in the longitudinal position\n",
    "        # and transform the longitudinal position from [-180, 180] to [0, 360]\n",
    "        crossing = False\n",
    "        \n",
    "        for c in range(len(long)-1):\n",
    "            if np.abs((long[c+1]-long[c])) > 100:\n",
    "                long = np.where(long <= 0, long + 360, long)\n",
    "                crossing = True\n",
    "                break\n",
    "\n",
    "        # Low-pass trajectories\n",
    "        b, a = signal.butter(6, lowpass_frequency, 'low', analog = False)\n",
    "        lat = signal.filtfilt(b, a, lat)\n",
    "        b, a = signal.butter(6, lowpass_frequency, 'low', analog = False)\n",
    "        long = signal.filtfilt(b, a, long)\n",
    "        \n",
    "        # If there is a crossing, then retransform coordinate back into range [-180, 180]\n",
    "        if crossing:\n",
    "            long = np.where(long >= 180, long - 360, long)\n",
    "        \n",
    "        return lat, long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558c38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in : \n",
    "## floaters : drifter ID\n",
    "\n",
    "## out :\n",
    "## floaters.csv : applies filter_data() to data from \"floaters.csv\"\n",
    "\n",
    "def low_pass(floaters, time0, path0, cutoff, lat_mean, f, interval_, filtering):\n",
    "    data = pd.read_csv(\"%sfiltered/%s.csv\" % (path0,floaters))\n",
    "    \n",
    "    ## disregards files with less than 21 data points ( required for interpolation of)\n",
    "    if(len(data)<=21):\n",
    "        return 1\n",
    "    lat = []\n",
    "    long = []\n",
    "    ## read latitude longitude data into \"lat\", \"long\"\n",
    "    for i in range(len(data)):\n",
    "        lat = np.append(lat,data['lat'][i]) \n",
    "        long = np.append(long,data['long'][i])\n",
    "    timef = [utc_to_minutes(data['time'][0],time0)]\n",
    "    \n",
    "    ## read time steps from initial time \"time0\" corresponding to \"lat\", \"long\" into \"timef\" (in minutes) \n",
    "    for i in range(len(data)-1):\n",
    "        dt = utc_to_minutes(data['time'][i+1],data['time'][i])\n",
    "        timef = np.append(timef, dt+timef[i]) \n",
    "\n",
    "    ##start point of interpolated data (first timestep in \"time\" rounded to next hour )    \n",
    "    time0_ = math.ceil(utc_to_minutes(data['time'][0],time0)/60)*60\n",
    "    \n",
    "    ##end point of interpolated data (last timestep in \"time\" rounded to previous hour)\n",
    "    time1_ = math.floor((timef[-1]+60)/60)*60\n",
    "    \n",
    "    #interpolation interval in minutes\n",
    "    interval = interval_*60\n",
    "    \n",
    "    ##array containing timesteps at which data is interpolated with time intervals \"interval\"\n",
    "    time = np.arange(time0_,time1_,interval) \n",
    "    time11 = np.arange(time0_,time1_,60)\n",
    "    \n",
    "    ##interpolate latitude, longitude at time steps in \"time\" into lat_interp, long_interp\n",
    "    lat_interp1 = scipy.interpolate.interp1d(timef[:], lat[:])\n",
    "    lat_interp = lat_interp1(time[:])   \n",
    "    long_interp1 = scipy.interpolate.interp1d(timef[:], long[:])\n",
    "    long_interp = long_interp1(time[:])\n",
    "    \n",
    "    ## filter interpolated data\n",
    "    if filtering:\n",
    "        lat_filt, long_filt = filter_data(lat_interp,long_interp, cutoff, lat_mean, f)\n",
    "    else:\n",
    "        lat_filt, long_filt = lat_interp, long_interp\n",
    "    #\n",
    "    \n",
    "    ## read interpolated, filtered data back into csv file\n",
    "    for i in range(len(time)):\n",
    "        data.loc[i,('lat')] = lat_filt[i]\n",
    "        data.loc[i,('long')] = long_filt[i]\n",
    "        data.loc[i,('time')] = minutes_to_utc(time[i],time0)\n",
    "    i = 0\n",
    "    for i in range(len(time), len(time11)):\n",
    "        data = data.iloc[:i]\n",
    "    data.to_csv(\"%sfiltered/%s.csv\" % (path0,floaters),columns = ['time', 'lat', 'long', 'temp', 'pressure'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b84a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47c4fd21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Mario\\anaconda3\\envs\\TBarrier\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (3,4,5,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019259e54b9e4a39864ad479fee07bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding Drifter IDs:   0%|          | 0/2884387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1073f6facc404689e450b15c66f441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Drifters:   0%|          | 0/1812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1812 drifters in download file\n",
      "316 drifters match spatial, temporal range\n",
      "19 drifters with less than 21 data points\n",
      "7 drifter with gap larger than 12 hours\n",
      "35 drifters starting or stopping during interval\n",
      "35 drifters with less than 21 data points after applying conditions\n",
      "262 valid drifters found\n",
      "--- 261.0102560520172 seconds ---\n"
     ]
    }
   ],
   "source": [
    "## main:\n",
    "## data : all drifter data from x.csv\n",
    "## time0 , time: temporal range of interest\n",
    "## lat0, lat, long0, long : spatial range considered\n",
    "## floaters : array containing all floater IDs found in \"data\"\n",
    "## - extracts all drifter IDs from \"data\"\n",
    "## - extracts drifter data from \"data\" with floaters_csv() until desired number of floaters found in temporal, \n",
    "##   spatial range of interest\n",
    "## - if more than 21 datapoints found: (minimal number required for interpolation)\n",
    "## - applies filter_() to csv files of drifters\n",
    "## - applies low_pass() to csv files of drifters\n",
    "##############################################################################################################\n",
    "\n",
    "##parameters:\n",
    "##spatial range of region of interest in Degrees\n",
    "long0 = -50\n",
    "long = 10\n",
    "lat0 = 30\n",
    "lat = 90\n",
    "\n",
    "##temporal range of region of interest\n",
    "#time0 = '2022-09-10T00:00:00Z'\n",
    "time0 = '2022-08-23T00:00:00Z' ##starttime\n",
    "#time = '2022-08-30T00:00:00Z' ##end time 7days\n",
    "#time = '2022-09-06T00:00:00Z' ##end time 14days\n",
    "time = '2022-09-13T00:00:00Z' ##end time 21days\n",
    "#time = '2022-09-20T00:00:00Z' ##end time 28days\n",
    "\n",
    "\n",
    "##########################\n",
    "##filtering parameters:\n",
    "\n",
    "##factor of cutoff frequency:\n",
    "#cutoff = 0.5\n",
    "#cutoff = 1.0\n",
    "cutoff = 1.5\n",
    "#cutoff = 1.25\n",
    "#cutoff = 2.0\n",
    "#cutoff = 2.5\n",
    "#cutoff = \"inf\"\n",
    "\n",
    "##sampling period (h)\n",
    "interval_ = 6\n",
    "##if low pass filter applied: \"filtering\" = \"True\" \n",
    "filtering = True\n",
    "\n",
    "################################################################################################################\n",
    "##Data Locations:\n",
    "##-path\n",
    "##--path_folders\n",
    "##---path_data\n",
    "##----path0\n",
    "##-----path_filtered\n",
    "##-----path_unfiltered\n",
    "##----raw_download\n",
    "\n",
    "##Path in PC\n",
    "path = \"C:/Mario/TBarrier/TBarrier/Untitled Folder/\"\n",
    "\n",
    "##Folder \"TRA_data\" in \"path\"\n",
    "path_folders = \"%sTRA_data/\" % path\n",
    "\n",
    "##Folder with spatial range in \"TRA_data\"\n",
    "path_data = \"%slong_%s_%s_lat_%s_%s_/\" % ( path_folders ,long0, long, lat0, lat)\n",
    "\n",
    "##Folder with Timeframe, filtering parameters in \"path_data\":\n",
    "\n",
    "##time interval between \"time0\" and \"time\" in days\n",
    "DD = np.int_(utc_to_minutes(time,time0)/60/24)\n",
    "\n",
    "if filtering == True:\n",
    "    path0 = \"%stime0_%s_%s_days/filter_%s_cutoff_%s/sampling period_%s/\" % (path_data,utc_(time0), DD,filtering, cutoff, interval_ )\n",
    "else:\n",
    "    path0 = \"%stime0_%s_%s_days/filter_%s/sampling period_%s/\" % (path_data,utc_(time0), DD,filtering, interval_)\n",
    "\n",
    "\n",
    "##Folder with filtered, unfiltered data\n",
    "path_filtered = \"%sfiltered/\" % path0\n",
    "path_unfiltered = \"%sunfiltered/\" %path0\n",
    "\n",
    "##Path of folders where filtered, unfiltered drifter csv files are saved in folder \"x\"\n",
    "Path('%s' % path_filtered).mkdir(parents=True, exist_ok=True)\n",
    "Path('%s' % path_unfiltered).mkdir(parents=True, exist_ok=True)\n",
    "#######################################\n",
    "##Download, Read data:\n",
    "\n",
    "##records time program takes to run\n",
    "start_time = TIME.time()\n",
    "\n",
    "##dowload drifter data from GDP:\n",
    "#website_path = \"http://osmc.noaa.gov/erddap/tabledap/OSMC_30day.csv?platform_code%2Cplatform_type%2Ctime%2Clatitude%2Clongitude%2Csst%2Cslp%2Clon360&platform_type=%22DRIFTING%20BUOYS%20(GENERIC)%22&orderBy(%22platform_code%2Ctime%22)\"\n",
    "#data = pd.read_csv(website_path)\n",
    "\n",
    "##read data from downloaded file:\n",
    "file_path = \"OSMC_30day_0133_b0b8_ef07.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.to_csv(\"%sraw_download.csv\" % path_folders , columns = ['platform_code', 'platform_type', 'time', 'latitude', 'longitude', 'sst', 'slp', 'lon360' ])\n",
    "#######################################\n",
    "##Extract drifters in range:\n",
    "\n",
    "## extract all drifter IDs in \"data\" into \"floaters\"\n",
    "floaters = [int(data['platform_code'][1])]\n",
    "for i in tqdm(range(2, len(data['platform_code'])-1), desc = \"Finding Drifter IDs\"):\n",
    "    if data['platform_code'][i]!= data['platform_code'][i+1]:\n",
    "        floaters = np.append(floaters,int(data['platform_code'][i]))\n",
    "\n",
    "## \"index\" iterates through \"data\" to extract drifter data (reduces computation time by starting extraction of next drifter at end of\n",
    "## previously extracted drifter)\n",
    "index = 0\n",
    "\n",
    "##records number of extracted drifters: \n",
    "k = 0\n",
    "##records number of drifters matching spatial, temporal range at any timestep\n",
    "a = 0\n",
    "b = 0\n",
    "c = 0\n",
    "gap_ = 0\n",
    "gap_1 = 0\n",
    "## end latitude, longitude, TRA value of extracted drifters in \"Floaters\":\n",
    "lat_c = []\n",
    "long_c = []\n",
    "TRA = []\n",
    "Floaters = []\n",
    "\n",
    "##average latitude of Region of interest\n",
    "lat_mean = (lat0+lat)/2\n",
    "\n",
    "##sampling frequency low pass filter (1/6h)\n",
    "fs = 6/interval_\n",
    "\n",
    "##iterate through \"data\" extracting drifters:\n",
    "#while i in range(len(floaters)) and k < floaters_nr:\n",
    "for i in tqdm(range(len(floaters)), desc = \"Extracting Drifters\"):\n",
    "    \n",
    "    ## read data corresponding to drifter \"floater[i]\" between \"time0\" and \"time\" in range of \"lat0\", \"lat\", \"long0\", \"long\"\n",
    "    ##into csv file \"floaters[i]_unfiltered\".csv:\n",
    "    j, index = floater_csv(floaters[i],data, time0, time, lat0, lat, long0, long, index, path0)  \n",
    "    if j >= 1:\n",
    "        a+= 1\n",
    "    ## if more than 21 data points in csv file \"floaters[i]\"_unfiltered.csv data is filtered:\n",
    "    if j >21: \n",
    "        b +=1\n",
    "        ##if more than 21 data points remaining after data points not corresponding to drifter trajectory are removed\n",
    "        ## the remaining data points are interpolated, low pass filtered and read into \"floaters[i]\".csv:\n",
    "        len_data, gap , gap1 = filter_(floaters[i],time0,time, path0)\n",
    "        gap_ += gap\n",
    "        gap_1 += gap1\n",
    "        if len_data > 21:\n",
    "            c+= 1\n",
    "            Floaters = np.append(Floaters,floaters[i])         \n",
    "            low_pass(floaters[i], time0, path0, cutoff, lat_mean , fs, interval_, filtering)            \n",
    "            k+=1\n",
    "            \n",
    "        ## if less than 21 data points remain all files corresponding to drifter \"floaters[i]\" are deleted\n",
    "        else:\n",
    "            os.remove(\"%s%s.csv\" % (path_filtered,floaters[i]))\n",
    "            os.remove(\"%s%s_unfiltered.csv\" % (path_unfiltered,floaters[i]))\n",
    "        \n",
    "    elif j <=21 and j > 0:\n",
    "        os.remove(\"%s%s_unfiltered.csv\" % (path_unfiltered,floaters[i]))\n",
    "    i+=1\n",
    "print(len(floaters),\"drifters in download file\")\n",
    "print(a, \"drifters match spatial, temporal range\")\n",
    "print(a-b, \"drifters with less than 21 data points\")\n",
    "print(gap_,\"drifter with gap larger than 12 hours\")\n",
    "print(gap_1,\"drifters starting or stopping during interval\")\n",
    "print(b-c, \"drifters with less than 21 data points after applying conditions\")\n",
    "print(k,\"valid drifters found\")\n",
    "print(\"--- %s seconds ---\" % (TIME.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0776c473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tqdm.notebook import tqdm\\n\\nfor i in tqdm(range(199990)):\\n    pass\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(199990)):\n",
    "    pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0468f2b0",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d104c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efde6b26",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
